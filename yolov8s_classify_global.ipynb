{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d121b79",
   "metadata": {},
   "source": [
    "# YOLOv8 Classification: Train + Validate + Report (Global Python)\n",
    "> ใช้กับ `ultralytics` รุ่นที่รองรับ `yolov8s-cls.pt`  \n",
    "> โครงสร้าง dataset แบบแยกโฟลเดอร์:  \n",
    "```\n",
    "dataset/\n",
    "  train/\n",
    "    classA/ img1.jpg ...\n",
    "    classB/ img2.jpg ...\n",
    "  val/\n",
    "    classA/ ...\n",
    "    classB/ ...\n",
    "  test/\n",
    "    classA/ ...\n",
    "    classB/ ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41746c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ติดตั้งไลบรารีที่จำเป็น (ใน Python global ของคุณ)\n",
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install ultralytics==8.2.103 matplotlib pandas scikit-learn\n",
    "\n",
    "# สำหรับ PyTorch: เลือก wheel ให้ตรงกับ CUDA ของคุณ (12.1 หรือ 12.4)\n",
    "# ตัวอย่างติดตั้ง CUDA 12.4:\n",
    "# !python -m pip install --index-url https://download.pytorch.org/whl/cu124 torch torchvision\n",
    "# หรือ CUDA 12.1:\n",
    "# !python -m pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, platform\n",
    "import torch\n",
    "import matplotlib, pandas\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "print(\"Matplotlib:\", matplotlib.__version__)\n",
    "print(\"Pandas:\", pandas.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e564da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\\\n",
    "from pathlib import Path\n",
    "\n",
    "# ===== ปรับพาธตามเครื่องคุณ =====\n",
    "PROJECT_DIR = Path(r\"D:\\herbSkin_Project66\")\n",
    "DATASET_DIR = PROJECT_DIR / r\"Dataset\\herb2\"   # ต้องมี train/val/test\n",
    "MODEL_WEIGHTS = \"yolov8s-cls.pt\"              # โมเดลสำหรับ classification\n",
    "\n",
    "# Training params\n",
    "EPOCHS = 50\n",
    "BATCH  = 32\n",
    "IMGSZ  = 224\n",
    "WORKERS = 4\n",
    "\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)\n",
    "print(\"DATASET_DIR:\", DATASET_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b8f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตรวจสอบโครงสร้าง dataset และรายชื่อคลาส\n",
    "import os\n",
    "\n",
    "def list_classes(split_dir: Path):\n",
    "    classes = []\n",
    "    if split_dir.exists():\n",
    "        for p in sorted([d for d in split_dir.iterdir() if d.is_dir()]):\n",
    "            classes.append(p.name)\n",
    "    return classes\n",
    "\n",
    "train_dir = DATASET_DIR / \"train\"\n",
    "val_dir   = DATASET_DIR / \"val\"\n",
    "test_dir  = DATASET_DIR / \"test\"\n",
    "\n",
    "print(\"Exist(train):\", train_dir.exists(), \" Exist(val):\", val_dir.exists(), \" Exist(test):\", test_dir.exists())\n",
    "print(\"Classes(train):\", list_classes(train_dir))\n",
    "print(\"Classes(val):\", list_classes(val_dir))\n",
    "print(\"Classes(test):\", list_classes(test_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c46f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# เทรนโมเดล YOLOv8 Classification\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(MODEL_WEIGHTS)  # yolov8s-cls.pt\n",
    "\n",
    "results = model.train(\n",
    "    data=str(DATASET_DIR),\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMGSZ,\n",
    "    batch=BATCH,\n",
    "    workers=WORKERS,\n",
    "    patience=20,\n",
    "    lr0=0.001,\n",
    "    optimizer='AdamW',\n",
    "    verbose=True\n",
    ")\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ประเมินผลบน val (หรือ test)\n",
    "val_metrics = model.val(split='val', imgsz=IMGSZ, batch=BATCH, workers=WORKERS)\n",
    "val_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc562a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้าง Confusion Matrix จากชุด val\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = sorted([d.name for d in (DATASET_DIR / \"val\").iterdir() if d.is_dir()])\n",
    "class_to_idx = {c:i for i, c in enumerate(class_names)}\n",
    "\n",
    "image_paths = []\n",
    "y_true = []\n",
    "for c in class_names:\n",
    "    cls_dir = DATASET_DIR / \"val\" / c\n",
    "    for img in cls_dir.rglob(\"*\"):\n",
    "        if img.suffix.lower() in {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"}:\n",
    "            image_paths.append(str(img))\n",
    "            y_true.append(class_to_idx[c])\n",
    "\n",
    "preds = []\n",
    "batch_size = 64\n",
    "for i in range(0, len(image_paths), batch_size):\n",
    "    batch = image_paths[i:i+batch_size]\n",
    "    res = model.predict(batch, imgsz=IMGSZ, verbose=False)\n",
    "    for r in res:\n",
    "        preds.append(int(r.probs.top1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(preds)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "plt.figure(figsize=(8,8))\n",
    "disp.plot(xticks_rotation=45, values_format='d')\n",
    "plt.title(\"Confusion Matrix (val)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c47f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตัวอย่างการพยากรณ์ภาพเดี่ยว/โฟลเดอร์\n",
    "sample = str(next((DATASET_DIR / \"test\").rglob(\"*.*\")))  # หยิบไฟล์แรกใน test เป็นตัวอย่าง\n",
    "print(\"Sample:\", sample)\n",
    "res = model.predict(sample, imgsz=IMGSZ)\n",
    "print(res[0].probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export โมเดล (ถ้าต้องการ)\n",
    "# ตัวเลือก: onnx, openvino, coreml, engine(TensorRT), torchscript ฯลฯ\n",
    "# ตัวอย่าง:\n",
    "# model.export(format=\"onnx\", imgsz=IMGSZ, opset=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e794fa",
   "metadata": {},
   "source": [
    "## Tips\n",
    "- หากต้องการ **resume training**: ใส่ `resume=True` ใน `model.train(...)`\n",
    "- หากชุดข้อมูลไม่สมดุล ลองปรับ `lr0`, `batch` ให้เหมาะสม\n",
    "- สามารถใช้ global Python ได้ ไม่จำเป็นต้องสร้าง venv\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
